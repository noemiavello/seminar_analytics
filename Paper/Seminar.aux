\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\bibstyle{abbrvnat}
\babel@aux{english}{}
\citation{Forecast2}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\newlabel{Chapter:intro}{{1}{1}{Introduction}{}{}}
\citation{Forecast1}
\@writefile{toc}{\contentsline {section}{\numberline {2}Basics in probability forecast evaluation}{2}{}\protected@file@percent }
\newlabel{Chapter:Probability forecast}{{2}{2}{Basics in probability forecast evaluation}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The CEP}{2}{}\protected@file@percent }
\newlabel{Chapter:CEP}{{2.1}{2}{The CEP}{}{}}
\newlabel{eq:CEP}{{2.1}{2}{The CEP}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Calibration}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Probability forecast and CEP relation for calibration}{2}{}\protected@file@percent }
\newlabel{eq: expected}{{2.2}{2}{Probability forecast and CEP relation for calibration}{}{}}
\citation{reliability1}
\citation{roc1}
\newlabel{eq: calibration}{{2.3}{3}{Probability forecast and CEP relation for calibration}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}How to assess calibration}{3}{}\protected@file@percent }
\newlabel{e:record}{{2.4}{4}{How to assess calibration}{}{}}
\newlabel{e:recalibrated}{{2.5}{4}{How to assess calibration}{}{}}
\newlabel{e:sdecomposition}{{2.6}{4}{How to assess calibration}{}{}}
\citation{roc1}
\newlabel{e:scoring}{{2.7}{5}{How to assess calibration}{}{}}
\newlabel{e:dec_scoring}{{2.8}{5}{How to assess calibration}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Discrimination analysis via ROC curve}{5}{}\protected@file@percent }
\citation{roc3}
\citation{roc1}
\citation{roc2}
\newlabel{e:distribution}{{2.9}{6}{Discrimination analysis via ROC curve}{}{}}
\newlabel{e:hit_rate}{{2.10}{6}{Discrimination analysis via ROC curve}{}{}}
\newlabel{e:far}{{2.11}{6}{Discrimination analysis via ROC curve}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}The Area Under the Curve (AUC)}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Raw ROC diagnostics and ROC curves}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Reliability diagrams (a and b). Under the binning and counting approach, a reliability diagram is displayed with 10 equally spaced bins for selection (a). Furthermore, a CORP reliability diagram (b). The forecast values for n = 92 are displayed as a distribution in the histograms at the bottom. The original ROC curves for the forecasts $x_{1},...,x_{n}$ from (\ref {e:record}) are displayed in Panel (c).}}{7}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:layout1}{{1}{7}{The Area Under the Curve (AUC)}{}{}}
\newlabel{e:bivariate}{{2.12}{7}{Raw ROC diagnostics and ROC curves}{}{}}
\citation{roc2}
\citation{roc3}
\citation{roc1}
\citation{statistical}
\citation{roc2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Concave ROC curves }{8}{}\protected@file@percent }
\citation{roc2}
\newlabel{e:likelihood}{{2.13}{9}{Concave ROC curves }{}{}}
\newlabel{e:conditional}{{2.14}{9}{Concave ROC curves }{}{}}
\newlabel{e:likelihood_ratio}{{2.15}{9}{Concave ROC curves }{}{}}
\newlabel{e:sqasduared}{{2.16}{9}{Concave ROC curves }{}{}}
\newlabel{e:con_prob}{{2.17}{9}{Concave ROC curves }{}{}}
\citation{precision}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The original ROC curve transforms into its concave hull, as seen by concave ROC curves from the PAV re-calibrated forecasts.}}{10}{}\protected@file@percent }
\newlabel{fig:concave_sim}{{2}{10}{Concave ROC curves }{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}ROC alternatives}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Precision-recall curves}{11}{}\protected@file@percent }
\newlabel{e:recall}{{3.1}{11}{Precision-recall curves}{}{}}
\newlabel{e:prec}{{3.2}{11}{Precision-recall curves}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Precision-recall curve for simulated application.}}{11}{}\protected@file@percent }
\newlabel{fig:Precision_recall_sim}{{3}{11}{Precision-recall curves}{}{}}
\citation{roc1}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}MCB-DSC plots}{12}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The Brier score and the logarithmic score are the two MCB-DSC graphs used to predict the likelihood of simulated data using isotonic regression. Forecasts that are better (above the line) and worse (below the line) than this baseline are distinguished by the thick green line. The green square at the origin represents the ex post best constant forecast, or the unconditional event frequency.}}{12}{}\protected@file@percent }
\newlabel{fig:mcb}{{4}{12}{MCB-DSC plots}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Empirical application}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Description of the data set}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Application}{13}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Reliability diagrams based on the binning and counting approach were displayed in plots (a), (c), and (e). For each of the three models use m = 10 equally spaced bins. In addition, the CORP reliability diagrams in (b), (d), and (f) illustrate how the PAV-calibrated probability is plotted against the original prediction value.}}{14}{}\protected@file@percent }
\newlabel{fig:rel_corp}{{5}{14}{Application}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Concave ROC curves from the PAV re-calibrated forecasts demonstrate that the original ROC curve morphs into its concave hull}}{15}{}\protected@file@percent }
\newlabel{fig:roc_app}{{6}{15}{Application}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Precision-recall curves for logistic, random forest, and naive bayes models.}}{16}{}\protected@file@percent }
\newlabel{fig:Precision_recall_app}{{7}{16}{Application}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces MCB-DSC plots for the logistic, naive bayes and random forest probability forecasts under (a) the Brier score and (b) the logarithmic score.}}{16}{}\protected@file@percent }
\newlabel{fig:app_MCBDSC}{{8}{16}{Application}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{17}{}\protected@file@percent }
\bibdata{bibexample}
\bibcite{reliability1}{{1}{2021}{{Dimitriadis et~al.}}{{Dimitriadis, Gneiting, and Jordan}}}
\bibcite{roc1}{{2}{2023}{{Dimitriadis et~al.}}{{Dimitriadis, Gneiting, Jordan, and Vogel}}}
\bibcite{precision}{{3}{2018}{{Fayzrakhmanov et~al.}}{{Fayzrakhmanov, Kulikov, and Repp}}}
\bibcite{roc2}{{4}{2022}{{Gneiting and Vogel}}{{}}}
\bibcite{roc3}{{5}{2022}{{Gneiting and Walz}}{{}}}
\bibcite{statistical}{{6}{2021}{{James. et~al.}}{{James., Witten., Hastie., and Tibshirani.}}}
\bibcite{Forecast2}{{7}{1992}{{Murphy and Winkler}}{{}}}
\bibcite{Forecast1}{{8}{2010}{{Roopesh and Tilmann}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{18}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{19}{}\protected@file@percent }
\gdef \@abspage@last{22}
